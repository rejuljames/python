{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import hashlib\n",
    "import io\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tarfile\n",
    "from urllib import urlretrieve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\" Download and unzip data.\"\"\"\n",
    "    urlretrieve('https://www.dropbox.com/s/xk4glpk61q3qrg2/imdb.tgz?dl=1', 'imdb.tgz')\n",
    "    tar = tarfile.open(\"imdb.tgz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    \n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirectories are:['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "path = 'data'\n",
    "print('subdirectories are:' + str(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    \"\"\" Return a list of file names in this directory that end in .txt \n",
    "    The list should be sorted alphabetically by file name.\n",
    "    Params:\n",
    "        path....a directory containing .txt review files.\n",
    "    Returns:\n",
    "        a list of .txt file names, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    l = []\n",
    "    import glob, os\n",
    "    import os\n",
    "    k = os.chdir(\"C:\\Users\\user\\OnlineSocial\\\\asg\\\\a3\\\\\")\n",
    "    p = os.getcwd()\n",
    "    os.chdir(p + \"\\\\\" + path)\n",
    "    r = os.getcwd()\n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        l.append(path+ \"\\\\\" + file)\n",
    "    l.sort()\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 200 positive and 200 negative training files\n",
      "first positive file: data\\train\\pos\\10057_9.txt\n",
      "first negative file: data\\train\\neg\\10108_1.txt\n"
     ]
    }
   ],
   "source": [
    "pos_train_files = get_files(path + os.sep + 'train' + os.sep + 'pos')\n",
    "neg_train_files = get_files(path + os.sep + 'train' + os.sep + 'neg')\n",
    "all_train_files = pos_train_files + neg_train_files\n",
    "\n",
    "print('found %d positive and %d negative training files' %\n",
    "      (len(pos_train_files), len(neg_train_files)))\n",
    "print('first positive file: %s' % pos_train_files[0])\n",
    "print('first negative file: %s' % neg_train_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\OnlineSocial\\asg\\a3\\data\\train\\neg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "first 3 and last 3 labels are: [1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def get_true_labels(file_names):\n",
    "    \"\"\"Return a *numpy array* of ints for the true sentiment labels of each file.\n",
    "    1 means positive, 0 means negative. Use the name of the file to determine\n",
    "    the true label.\n",
    "    Params:\n",
    "        file_names....a list of .txt file paths, e.g., data/train/pos/10057_9.txt\n",
    "    Returns:\n",
    "        a numpy array of 1 or 0 values corresponding to each element\n",
    "        of file_names, where 1 indicates a positive review, and 0\n",
    "        indicates a negative review.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "#    print file_names\n",
    "    count = 0\n",
    "    l = len(file_names)\n",
    "    print l\n",
    "    a=np.empty(len(file_names),dtype=int)\n",
    "    for k in file_names:\n",
    "        p = k.split('train\\\\')\n",
    "#        print p[1]\n",
    "        t = p[1].split('\\\\')\n",
    "#        q =  t[0].strip(\" \")\n",
    "        if t[0] == 'pos':\n",
    "            a[count]=1\n",
    "        if t[0] == 'neg':\n",
    "            a[count]=0\n",
    "        count = count + 1\n",
    "    return a\n",
    "\n",
    "        \n",
    "\n",
    "labels = get_true_labels(all_train_files)\n",
    "print('first 3 and last 3 labels are: %s' % str(labels[[1,2,3,-3,-2,-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"This is a great film!! The first time I saw it I thought it was absorbing from start to finish and I still do now. I may not have seen the play, but even if I had it wouldn't stop me thinking that the film is just as good.\""
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def file2string(filename):\n",
    "    return io.open(filename, encoding='utf8').readlines()[0]\n",
    "    \n",
    "file2string(pos_train_files[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'how',\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " 'an_underscore',\n",
       " 'is',\n",
       " 'not',\n",
       " 'really',\n",
       " 'punctuation']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is removed. Note that\n",
    "    underscore (_) is not considered punctuation.\n",
    "    UPDATE: To be more specific, a token is a sequence of \n",
    "    alphanumeric characters, i.e., [A-Za-z0-9_]. Non-ascii characters\n",
    "    are not considered to be part of tokens.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    \n",
    "    k = []\n",
    "#    asking  = \" Hi! How's it going??? an_underscore is not *really* punctuation.\"\n",
    "    text =  text.lower()\n",
    "    k = re.sub('\\W+', ' ', text).split()\n",
    "    return k\n",
    "    \n",
    "\n",
    "tokenize(\"Hi! How's it going??? an_underscore is not *really* punctuation.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix represents 400 documents with 10710 features\n",
      "first doc has terms:\n",
      "[128, 170, 202, 253, 260, 312, 355, 439, 504, 514, 560, 673, 683, 702, 750, 860, 869, 961, 985, 1013, 1222, 1254, 1312, 1341, 1403, 1444, 1451, 1469, 1504, 1658, 1665, 1743, 2465, 2537, 2996, 3109, 3206, 3229, 3356, 3368, 3515, 3634, 3706, 3716, 3759, 3810, 3926, 4015, 4059, 4061, 4087, 4139, 4205, 4207, 4222, 4309, 4366, 4384, 4412, 4435, 4472, 4510, 4524, 4631, 4690, 4757, 4798, 5062, 5074, 5225, 5274, 5287, 5289, 5312, 5360, 5418, 5609, 5610, 5646, 5693, 5761, 5888, 5932, 5948, 6116, 6243, 6258, 6294, 6424, 6440, 6579, 6620, 6676, 6696, 6860, 6942, 7094, 7626, 8052, 8248, 8336, 8341, 8474, 8767, 8988, 9204, 9412, 9436, 9440, 9505, 9508, 9523, 9550, 9558, 9634, 9684, 9690, 9835, 9855, 9857, 10047, 10337, 10353, 10431, 10441, 10446, 10448, 10519]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def do_vectorize(filenames, tokenizer_fn=tokenize, min_df=1,\n",
    "                 max_df=1., binary=True, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Convert a list of filenames into a sparse csr_matrix, where\n",
    "    each row is a file and each column represents a unique word.\n",
    "    Use sklearn's CountVectorizer: http://goo.gl/eJ2PJ5\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "    Return:\n",
    "        A tuple (X, vec), where X is the csr_matrix of feature vectors,\n",
    "        and vec is the CountVectorizer object.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    \n",
    "    vectorizer = CountVectorizer(input='filename',tokenizer=tokenizer_fn, binary=binary, max_df=max_df, min_df=min_df, ngram_range=(1, 1), dtype = int)\n",
    "    x = vectorizer.fit_transform(filenames)\n",
    "    return x, vectorizer\n",
    "   \n",
    "\n",
    "#    X = vectorizer.fit_transform(t['text'] for t in filenames)\n",
    "    \n",
    "matrix, vec = do_vectorize(all_train_files)\n",
    "print ('matrix represents %d documents with %d features' % (matrix.shape[0], matrix.shape[1]))\n",
    "print('first doc has terms:\\n%s' % (str(sorted(matrix[0].nonzero()[1]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first shuffled document data\\train\\pos\\5140_10.txt has label 1 and terms: [98, 170, 355, 384, 514, 720, 750, 780, 1225, 2234, 3356, 3682, 3916, 4015, 4397, 4690, 4798, 5074, 5080, 5764, 5948, 6579, 6782, 6950, 7899, 8186, 8587, 9045, 9508, 9550, 9609, 9827, 10003, 10421, 10640]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify. This is to randomize the order of the documents, but\n",
    "# in a way that is consistent across platforms.\n",
    "# See: http://stackoverflow.com/a/18992474/1756896\n",
    "# You should run this block once to get the shuffled data.\n",
    "def repeatable_random(seed):\n",
    "    hash = str(seed)\n",
    "    while True:\n",
    "        hash = hashlib.md5(hash).digest()\n",
    "        for c in hash:\n",
    "            yield ord(c)\n",
    "\n",
    "def repeatable_shuffle(X, y, filenames):\n",
    "    r = repeatable_random(42) \n",
    "    indices = sorted(range(X.shape[0]), key=lambda x: next(r))\n",
    "    return X[indices], y[indices], np.array(filenames)[indices]\n",
    "\n",
    "X, y, filenames = repeatable_shuffle(matrix, labels, all_train_files)\n",
    "\n",
    "print('first shuffled document %s has label %d and terms: %s' % \n",
    "      (filenames[0], y[0], sorted(X[0].nonzero()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do not modify. This creates a LogsticRegression object, which\n",
    "# you will use in the do_cross_validation method below.\n",
    "def get_clf():\n",
    "    return LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 accuracy=0.7125\n",
      "fold 1 accuracy=0.7750\n",
      "fold 2 accuracy=0.7750\n",
      "fold 3 accuracy=0.7250\n",
      "fold 4 accuracy=0.7125\n",
      "average cross validation accuracy=0.7400\n"
     ]
    }
   ],
   "source": [
    "def do_cross_validation(X, y, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform n-fold cross validation, calling get_clf() to train n\n",
    "    different classifiers. Use sklearn's KFold class: http://goo.gl/wmyFhi\n",
    "    Be sure not to shuffle the data, otherwise your output will differ.\n",
    "    Params:\n",
    "        X.........a csr_matrix of feature vectors\n",
    "        y.........the true labels of each document\n",
    "        n_folds...the number of folds of cross-validation to do\n",
    "        verbose...If true, report the testing accuracy for each fold.\n",
    "    Return:\n",
    "        the average testing accuracy across all folds.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    \n",
    "    \"\"\" Compute average cross-validation acccuracy.\"\"\"\n",
    "    cv = KFold(len(y), n_folds)\n",
    "    accuracies = []\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "        if verbose == True:\n",
    "            print ('fold %d accuracy=%.4f' %(fold,accuracy_score(y[test_idx], predicted)))\n",
    "        fold += 1\n",
    "    avg = np.mean(accuracies)\n",
    "    return avg\n",
    "    \n",
    "print('average cross validation accuracy=%.4f' %\n",
    "      do_cross_validation(X, y, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_expt(filenames, y, tokenizer_fn=tokenize,\n",
    "            min_df=1, max_df=1., binary=True,\n",
    "            ngram_range=(1,1), n_folds=5):\n",
    "    \"\"\"\n",
    "    Run one experiment, which consists of vectorizing each file,\n",
    "    performing cross-validation, and returning the average accuracy.\n",
    "    You should call do_vectorize and do_cross_validation here.\n",
    "    Params:\n",
    "        filenames.......list of review file names\n",
    "        y...............the true sentiment labels for each file\n",
    "        tokenizer_fn....the function used to tokenize each document\n",
    "        min_df..........remove terms from the vocabulary that don't appear\n",
    "                        in at least this many documents\n",
    "        max_df..........remove terms from the vocabulary that appear in more\n",
    "                        than this fraction of documents\n",
    "        binary..........If true, each documents is represented by a binary\n",
    "                        vector, where 1 means a term occurs at least once in \n",
    "                        the document. If false, the term frequency is used instead.\n",
    "        ngram_range.....A tuple (n,m) means to use phrases of length n to m inclusive.\n",
    "                        E.g., (1,2) means consider unigrams and bigrams.\n",
    "        n_folds.........The number of cross-validation folds to use.\n",
    "    Returns:\n",
    "        the average cross validation testing accuracy.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    matrix, vec = do_vectorize(filenames,tokenizer_fn=tokenizer_fn,min_df=min_df, max_df=max_df,binary = binary , ngram_range=(1,1))\n",
    "    k= do_cross_validation(matrix, y,n_folds)\n",
    "    return k \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy using default settings: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('accuracy using default settings: %.4g' % do_expt(filenames, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.69999999999999996, 0.73999999999999999, 0.745, 0.75250000000000006]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEQCAYAAACugzM1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x180c8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_n_folds(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of n_folds parameter in the do_expt \n",
    "    function to be in [2,5,10,20]. For each setting, call do_expt and \n",
    "    store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per fold.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    t = []\n",
    "    k = [2,5,10,20]\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.xlim((2,20))\n",
    "    plt.ylim((0.70, 0.76))\n",
    "    for i in k:\n",
    "        p = do_expt(filenames, y, tokenizer_fn=tokenize, min_df=1, max_df=1., binary=True,ngram_range=(1,1), n_folds=i)\n",
    "        t.append(p)\n",
    "    plt.plot(k, t, marker = 'o')\n",
    "    plt.xlabel('n_folds')\n",
    "    plt.ylabel('accuracies')\n",
    "    return t\n",
    "    \n",
    "compare_n_folds(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think accuracy increases as the number of folds increases?\n",
    "\n",
    "When we decrease the number of folds, it will be biase error estimate value and it will be less variable also. When we increase number of folds the error estimate wont be biased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73999999999999999, 0.69999999999999996]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_binary(filenames, y):\n",
    "    \"\"\"\n",
    "    How does the binary parameter affect results? \n",
    "    Call do_expt twice, once with binary=True, and once with binary=False.\n",
    "    Return the average accuracies for each. Use the default parameters for the\n",
    "    remaining arguments in do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies. The first entry\n",
    "        is for binary=True, the second is for binary=False.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    p = []\n",
    "    p.append(do_expt(filenames, y, binary=True))\n",
    "    p.append(do_expt(filenames, y, binary=False))\n",
    "    return p\n",
    "compare_binary(filenames, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " '!',\n",
       " 'how',\n",
       " \"'\",\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " '?',\n",
       " '?',\n",
       " '?',\n",
       " 'an_underscore',\n",
       " 'is',\n",
       " 'not',\n",
       " '*',\n",
       " 'really',\n",
       " '*',\n",
       " 'punctuation',\n",
       " '.']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_with_punct(text):\n",
    "    \"\"\"Given a string, return a list of tokens such that: (1) all\n",
    "    tokens are lowercase, (2) all punctuation is kept as separate tokens.\n",
    "    Note that underscore (_) is not considered punctuation.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    l=''\n",
    "    text = text.lower()\n",
    "    for t in text:\n",
    "        if re.match('\\W+',t):\n",
    "            l=l+' '+t+' '\n",
    "        else:\n",
    "            l=l+t\n",
    "    return l.split()\n",
    "    \n",
    "\n",
    "tokenize_with_punct(\"Hi! How's it going??? an_underscore is not *really* punctuation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_good',\n",
       " 'not_.',\n",
       " 'in',\n",
       " 'fact',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'not_even',\n",
       " 'not_really',\n",
       " 'a',\n",
       " 'movie']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_with_not(text):\n",
    "    \"\"\"Does the same thing as tokenize_with_punct, with the following difference:\n",
    "    whenever the term 'not' appears, change the two subsequent tokens to have the prefix\n",
    "    'not_' prior to the token. See the example below. You may call \n",
    "    tokenize_with_punct as a subroutine.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    k = tokenize_with_punct(text)\n",
    "#    print k\n",
    "    r =1\n",
    "    for i in range(0,len(k) - 1,r):\n",
    "        if k[i] == 'not' and  i < len(k) - 2:\n",
    "            k[i+1] = 'not_' + k[i+1]\n",
    "            k[i+2] = 'not_' + k[i+2]\n",
    "        else:\n",
    "            if k[i] == 'not' and i == len(k) -2:\n",
    "                k[i+1] = 'not_' + k[i+1]\n",
    "            \n",
    "    return k\n",
    "            \n",
    "\n",
    "tokenize_with_not(\"This movie is not good. In fact, it is not even really a movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the fiancée of not Henri\n",
      "tokenize: not, the, fianc, e, of, not, henri\n",
      "tokenize_with_punct: not, the, fianc, é, e, of, not, henri\n",
      "tokenize_with_not: not, not_the, not_fianc, é, e, of, not, not_henri\n"
     ]
    }
   ],
   "source": [
    "# To keep things simple, we'll pretend that non-ascii \n",
    "# characters are punctuation.\n",
    "nonascii_string = u'not the fiancée of not Henri'\n",
    "print nonascii_string\n",
    "print('tokenize: %s' % \n",
    "      ', '.join(tokenize(nonascii_string)))\n",
    "print('tokenize_with_punct: %s' %\n",
    "      ', '.join(tokenize_with_punct(nonascii_string)))\n",
    "print('tokenize_with_not: %s' %\n",
    "      ', '.join(tokenize_with_not(nonascii_string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73999999999999999, 0.74499999999999988, 0.74749999999999994]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_expt(all_train_files, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    How does the tokenizer affect results? \n",
    "    Call do_expt three times, using three different tokenizers:\n",
    "    1- tokenize\n",
    "    2- tokenize_with_punct\n",
    "    3- tokenize_with_not\n",
    "    Return the average cross-validation accuracy for each approach,\n",
    "    in the above order. Use the default parameters for all other \n",
    "    arguments to do_expt.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies for each tokenizer.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    k = []\n",
    "    k.append(do_expt(filenames, y, tokenizer_fn=tokenize))\n",
    "    k.append(do_expt(filenames, y, tokenizer_fn=tokenize_with_punct))\n",
    "    k.append(do_expt(filenames, y, tokenizer_fn=tokenize_with_not))\n",
    "    return k\n",
    "\n",
    "    \n",
    "\n",
    "tokenizer_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.74749999999999994,\n",
       " 0.76000000000000001,\n",
       " 0.75000000000000011,\n",
       " 0.74249999999999994,\n",
       " 0.74999999999999989,\n",
       " 0.74249999999999994,\n",
       " 0.74749999999999994,\n",
       " 0.73750000000000004,\n",
       " 0.72750000000000004,\n",
       " 0.73000000000000009]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEQCAYAAABxzUkqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1630a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def min_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of min_df parameter in the do_expt \n",
    "    function to be ints in the range (1,10) (inclusive). For each setting,\n",
    "    call do_expt and store the resulting accuracy. Plot the accuracies for each setting.\n",
    "    Also return the list of accuracies. Use the default value for all\n",
    "    other arguments to the do_expt function, except that the tokenizer\n",
    "    should be tokenize_with_not.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per min_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    k = [1,2,3,4,5,6,7,8,9,10]\n",
    "    l=[]\n",
    "    plt.xlim((1,10))\n",
    "    plt.ylim((0.725, 0.760))\n",
    "    for i in k:\n",
    "        l.append(do_expt(filenames, y, min_df=i, tokenizer_fn=tokenize_with_not))\n",
    "    plt.plot(k, l,marker = 'o')  \n",
    "    plt.xlabel('min_dif')\n",
    "    plt.ylabel('accuracies')\n",
    "    return l\n",
    "\n",
    "    \n",
    "\n",
    "min_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.76000000000000001,\n",
       " 0.75250000000000006,\n",
       " 0.76749999999999996,\n",
       " 0.76000000000000001,\n",
       " 0.75250000000000006,\n",
       " 0.74999999999999989,\n",
       " 0.77000000000000013,\n",
       " 0.76250000000000007,\n",
       " 0.75749999999999995,\n",
       " 0.76000000000000001]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEQCAYAAACa+vIpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17b8fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def max_df_expt(filenames, y):\n",
    "    \"\"\"\n",
    "    Vary the setting of max_df parameter in the do_expt \n",
    "    function to be one of [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.].\n",
    "    For each setting, call do_expt and store the resulting accuracy.\n",
    "    Plot the accuracies for each setting. Also return the list of accuracies.\n",
    "    Use the default value for all other arguments to the do_expt function,\n",
    "    except that the tokenizer=tokenize_with_not and min_df=2.\n",
    "    Params:\n",
    "        filenames....list of training file names\n",
    "        y............true labels for each file (a numpy array)\n",
    "    Returns:\n",
    "        a list of average testing accuracies, one per max_df value.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    k = [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
    "    l=[]\n",
    "    plt.xlim((.1,1))\n",
    "    plt.ylim((0.745, 0.775))\n",
    "    for i in k:\n",
    "        l.append(do_expt(filenames, y ,tokenizer_fn=tokenize_with_not , max_df=i, min_df=2))\n",
    "    \n",
    "    plt.xlabel('max_dif')\n",
    "    plt.ylabel('accuracies')\n",
    "    plt.plot(k, l, marker = 'o')\n",
    "    return l\n",
    "    \n",
    "\n",
    "    \n",
    "max_df_expt(filenames, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll train our final classifier using our best settings.\n",
    "X, vec = do_vectorize(filenames, tokenizer_fn=tokenize_with_not,\n",
    "                      binary=True, min_df=2, max_df=.7)\n",
    "clf = get_clf()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(1L, 4734L)\n"
     ]
    }
   ],
   "source": [
    "print type(clf.coef_)\n",
    "print clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3021783  -0.31127296 -0.01907905 -0.13228897  0.05602542  0.16796849\n",
      " -0.11328267  0.03523083 -0.13081422 -0.05752848]\n",
      "[u'!', u'\"', u'#', u'$', u'%', u'&', u'(', u')', u'*', u'+']\n"
     ]
    }
   ],
   "source": [
    "# Here are the first 10 coefficients.\n",
    "print(clf.coef_[0][:10])\n",
    "# The features corresponding to them can be found using the vectorizer's get_feature_names method.\n",
    "print(vec.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top positive coefs: [(u'worth', 0.61202695820826092), (u'film', 0.54737364161552149), (u'have', 0.47928273189959941), (u'best', 0.46199108787267001), (u'great', 0.45368029926382336)]\n",
      "top negative coefs: [(u'worst', -0.85392289056204795), (u'nothing', -0.73758348631561066), (u'waste', -0.66700704570210267), (u'boring', -0.56750539181392734), (u'bad', -0.56574411469931851)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_coefficients(clf, vec, n=10):\n",
    "    \"\"\" Get the top n coefficients for each class (positive/negative).\n",
    "    Params:\n",
    "        clf...a LogisticRegression object that has already been fit to data.\n",
    "        vec...a CountVectorizer\n",
    "        n.....the number of features to print per class.\n",
    "    Returns:\n",
    "        Two lists of tuples. The first list containts the top terms for the positive\n",
    "        class. Each entry is a tuple of (string, float) pairs, where\n",
    "        string is the feature name and float is the coefficient.\n",
    "        The second list is the same but for the negative class.\n",
    "        In each list, entries should be sorted in descending order of \n",
    "        absolute value.\"\"\"\n",
    "    ###TODO\n",
    "    ##\n",
    "    pos = []\n",
    "    neg = []\n",
    "    voc = vec.vocabulary_\n",
    "    \n",
    "    terms=np.array([x[0] for x in sorted(voc.items(),key=lambda x:x[1])])\n",
    "    coef=clf.coef_[0]\n",
    "    s=np.argsort(coef)\n",
    "    topi=s[::-1][:n]\n",
    "    bottomi=s[:n]\n",
    "    pos = [(n,c) for n, c in zip(terms[topi],coef[topi])]\n",
    "    neg = [(n,c) for n, c in zip(terms[bottomi],coef[bottomi])]\n",
    "    return pos,neg\n",
    "\n",
    "pos_coef, neg_coef = get_top_coefficients(clf, vec, n=5)\n",
    "print('top positive coefs: %s' % str(pos_coef))\n",
    "print('top negative coefs: %s' % str(neg_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\test\\\\neg\\\\output.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-4825178b421c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Note that we call .transform, not .fit_transform, since we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# don't want to learn a new vocabulary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_test_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_test_files\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_test_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X_test represents %d documents with %d features'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 236\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\test\\\\neg\\\\output.txt'"
     ]
    }
   ],
   "source": [
    "# Do not modify.\n",
    "pos_test_files = get_files(path + os.sep + 'test' + os.sep + 'pos')\n",
    "neg_test_files = get_files(path + os.sep + 'test' + os.sep + 'neg')\n",
    "all_test_files = pos_test_files + neg_test_files\n",
    "# Note that we call .transform, not .fit_transform, since we \n",
    "# don't want to learn a new vocabulary.\n",
    "X_test = vec.transform(all_test_files)\n",
    "y_test = np.array([1] * len(pos_test_files) + [0] * len(neg_test_files))\n",
    "print('X_test represents %d documents with %d features' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('y_test has %d positive and %d negative labels' % (len(np.where(y_test==1)[0]),\n",
    "                                                          len(np.where(y_test==0)[0])))\n",
    "print('first testing file is %s' % all_test_files[0])\n",
    "print('last testing file is %s' % all_test_files[-1])\n",
    "print('testing accuracy=%.4g' % accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not modify.\n",
    "def index_of_term(vec, term):\n",
    "    \"\"\" This returns the column index corresponding to this term.\"\"\"\n",
    "    return vec.get_feature_names().index(term)\n",
    "\n",
    "index_of_term(vec, 'film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy=0.7925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_after_removing_features(X, y, vec, features_to_remove):\n",
    "    \"\"\"\n",
    "    Set to 0 the columns of X corresponding to the terms in features_to_remove. \n",
    "    Then, train a new classifier on X and y and return the result.\n",
    "    Params:\n",
    "        X....................the training matrix\n",
    "        y....................the true labels for each row in X\n",
    "        features_to_remove...a list of strings (entries in the vocabulary) that\n",
    "                             should be removed from X\n",
    "    Returns:\n",
    "       The classifier fit on the modified X data.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    for t in features_to_remove:\n",
    "        n = index_of_term(vec, t)\n",
    "        for m in range(0,X.shape[0]):\n",
    "            X[m,n] = 0\n",
    "    clf = get_clf()\n",
    "    clf.fit(X,y)\n",
    "    return clf\n",
    "   \n",
    "    \n",
    "clf = train_after_removing_features(X.copy(), y, vec, ['film'])\n",
    "print('testing accuracy=%.5g' % accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'filename': 'data\\\\test\\\\pos\\\\9713_8.txt',\n",
       "  'index': 194,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.991884594856553,\n",
       "  'probas': array([ 0.99188459,  0.00811541]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\pos\\\\4742_10.txt',\n",
       "  'index': 115,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.96939232995777913,\n",
       "  'probas': array([ 0.96939233,  0.03060767]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\neg\\\\479_3.txt',\n",
       "  'index': 305,\n",
       "  'predicted': 1,\n",
       "  'probability': 0.96389380477771303,\n",
       "  'probas': array([ 0.0361062,  0.9638938]),\n",
       "  'truth': 0},\n",
       " {'filename': 'data\\\\test\\\\pos\\\\1617_7.txt',\n",
       "  'index': 65,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.93559658547451197,\n",
       "  'probas': array([ 0.93559659,  0.06440341]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\neg\\\\2383_4.txt',\n",
       "  'index': 266,\n",
       "  'predicted': 1,\n",
       "  'probability': 0.90494861533404913,\n",
       "  'probas': array([ 0.09505138,  0.90494862]),\n",
       "  'truth': 0},\n",
       " {'filename': 'data\\\\test\\\\pos\\\\880_8.txt',\n",
       "  'index': 185,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.90444261011791938,\n",
       "  'probas': array([ 0.90444261,  0.09555739]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\pos\\\\11657_10.txt',\n",
       "  'index': 37,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.89960075674283912,\n",
       "  'probas': array([ 0.89960076,  0.10039924]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\pos\\\\4872_8.txt',\n",
       "  'index': 118,\n",
       "  'predicted': 0,\n",
       "  'probability': 0.88298928159129608,\n",
       "  'probas': array([ 0.88298928,  0.11701072]),\n",
       "  'truth': 1},\n",
       " {'filename': 'data\\\\test\\\\neg\\\\6931_1.txt',\n",
       "  'index': 342,\n",
       "  'predicted': 1,\n",
       "  'probability': 0.88134588453807305,\n",
       "  'probas': array([ 0.11865412,  0.88134588]),\n",
       "  'truth': 0},\n",
       " {'filename': 'data\\\\test\\\\neg\\\\2858_2.txt',\n",
       "  'index': 272,\n",
       "  'predicted': 1,\n",
       "  'probability': 0.87610712380722111,\n",
       "  'probas': array([ 0.12389288,  0.87610712]),\n",
       "  'truth': 0}]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_errors(X_test, y_test, filenames, clf, n=10):\n",
    "    predicted = clf.predict(X_test)\n",
    "    predicted_proba = clf.predict_proba(X_test)    \n",
    "    l =[]\n",
    "    for i in range(len(predicted)):\n",
    "        dic ={}\n",
    "        probability = predicted_proba[i][predicted[i]]\n",
    "        # If we're very wrong.\n",
    "        if predicted[i] != y_test[i] :\n",
    "            dic['filename']=filenames[i]\n",
    "            dic['index']=i\n",
    "            dic['probas']=predicted_proba[i]\n",
    "            dic['truth']=y_test[i]\n",
    "            dic['probability'] = probability\n",
    "            dic['predicted'] = predicted[i]\n",
    "            l.append(dic)\n",
    "    m = sorted(l, key = lambda x: x['probability'], reverse =True)[:n]\n",
    "    return m\n",
    "errors = get_top_errors(X_test, y_test, all_test_files, clf)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for document data\\test\\pos\\10055_10.txt, the term most predictive of class 0 is no (index=2793)\n",
      "for document data\\test\\pos\\10055_10.txt, the term most predictive of class 1 is best (index=492)\n"
     ]
    }
   ],
   "source": [
    "def most_predictive_term_in_doc(instance, clf, class_idx):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        instance....one row in the X csr_matrix, corresponding to a document.\n",
    "        clf.........a trained LogisticRegression classifier\n",
    "        class_idx...0 or 1. The class for which we should find the most \n",
    "                    predictive term in this document.\n",
    "    Returns:\n",
    "        The index corresponding to the term that appears in this instance\n",
    "        and has the highest coefficient for class class_idx.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    # Given a document, find the term in it that is most strongly associated\n",
    "# with a given class label, according to a trained classifier.\n",
    "    coef = clf.coef_[0]     \n",
    "    term_indices = sorted(instance.indices, key =lambda X : coef[X])     \n",
    "    if class_idx == 0:\n",
    "            return term_indices[0]\n",
    "    else:\n",
    "        return term_indices[-1]\n",
    "    \n",
    "neg_idx = most_predictive_term_in_doc(X_test[0], clf, 0)\n",
    "pos_idx = most_predictive_term_in_doc(X_test[0], clf, 1)\n",
    "print('for document %s, the term most predictive of class 0 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[neg_idx], neg_idx))\n",
    "print('for document %s, the term most predictive of class 1 is %s (index=%d)' %\n",
    "      (all_test_files[0], vec.get_feature_names()[pos_idx], pos_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"no\" context with window 3: [u'so it was no \" last emperor']\n",
      "\"no\" context with window 5: [u'proudly ? so it was no \" last emperor \" ,']\n",
      "\"best\" context: [u\"it wasn ' t her best movie ever ? didn '\"]\n",
      "\"a\" contexts: [u\"to rate this movie at a 10 . i ' m\", u'think of it as an a + sociological study into the']\n"
     ]
    }
   ],
   "source": [
    "def find_contexts(filename, term, window=5):\n",
    "    \"\"\"\n",
    "    Find all context windows in which this term appears in this file.\n",
    "    You should use tokenize_with_not to tokenize this file. \n",
    "    \n",
    "    Params:\n",
    "        filename....the filename for this document.\n",
    "        term........the term to find\n",
    "        window......return this many tokens to the left and this many tokens to\n",
    "                    the right of every occurrence of term in this document\n",
    "    Returns:\n",
    "        a list of strings. Each string contains the matched context window.\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    ###\n",
    "    \n",
    "    text=file2string(filename)\n",
    "    tokens=tokenize_with_not(text)\n",
    "    token=[]\n",
    "    for i in range(1,len(tokens)):\n",
    "        if tokens[i]==term:\n",
    "            token.append(i)\n",
    "    l=[]\n",
    "    for tok in token:    \n",
    "        str=\"\"\n",
    "        for m in range(tok-window,tok):\n",
    "            str=str+tokens[m]+\" \"\n",
    "        str+=tokens[tok]\n",
    "        for m in range(tok+1,tok+window+1):\n",
    "            str=str+\" \"+tokens[m]\n",
    "        l.append(str)\n",
    "    return l\n",
    "\n",
    "# Here are some sample outputs on the first test document:\n",
    "print('\"no\" context with window 3: %s' % find_contexts(all_test_files[0], 'no', 3))\n",
    "print('\"no\" context with window 5: %s' % find_contexts(all_test_files[0], 'no', 5))\n",
    "print('\"best\" context: %s' % find_contexts(all_test_files[0], 'best'))\n",
    "print('\"a\" contexts: %s' % find_contexts(all_test_files[0], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document data\\test\\pos\\9713_8.txt misclassified as 0\n",
      "worst appears here:\n",
      "[u'know but they hid some of the best ( or worst depending on how you want to look at it ) ']\n",
      "\n",
      "document data\\test\\pos\\4742_10.txt misclassified as 0\n",
      "bad appears here:\n",
      "[u'vietnam war , and other significant events that smell so bad of a cover up that you have to hold your ']\n",
      "\n",
      "document data\\test\\neg\\479_3.txt misclassified as 1\n",
      "best appears here:\n",
      "[u'himself . thus , bruce is doing what he does best and no doubt his many fans will be pleased . ']\n",
      "\n",
      "document data\\test\\pos\\1617_7.txt misclassified as 0\n",
      "worst appears here:\n",
      "[u'took itself seriously which automatically takes it out of the worst movie list . that list is only for big budget ']\n",
      "\n",
      "document data\\test\\neg\\2383_4.txt misclassified as 1\n",
      "have appears here:\n",
      "[u'from \" d \\' ont ask d \\' ont tell have been translators ( they are now it major short supply ']\n",
      "\n",
      "document data\\test\\pos\\880_8.txt misclassified as 0\n",
      "1 appears here:\n",
      "[u\") : < br / > < br / > 1 vijay anand ' s direction 2 r d burman ' \"]\n",
      "\n",
      "document data\\test\\pos\\11657_10.txt misclassified as 0\n",
      "no appears here:\n",
      "[u'my heart out . their acting is so real ! no doubt about it that this movie is rated 4 and ']\n",
      "\n",
      "document data\\test\\pos\\4872_8.txt misclassified as 0\n",
      "? appears here:\n",
      "[u\". . . . . but who ' s complaining ? it ' s always fun to see the poor coyote \"]\n",
      "\n",
      "document data\\test\\neg\\6931_1.txt misclassified as 1\n",
      "worth appears here:\n",
      "[u\"skill , directing without direction , and acting without the worth of some backwater high school ' s freshman class play \"]\n",
      "\n",
      "document data\\test\\neg\\2858_2.txt misclassified as 1\n",
      "best appears here:\n",
      "[u'\" these are titles that tend to bring out the best in kevin s . tenney . ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_errors(errors, clf, X, vec, window=5):\n",
    "    for error in errors:\n",
    "        fidx = most_predictive_term_in_doc(X[error['index']], clf, error['predicted'])\n",
    "        term = vec.get_feature_names()[fidx]\n",
    "        print('document %s misclassified as %d' % (error['filename'], error['predicted']))\n",
    "        print('%s appears here:' % (term))\n",
    "        print(find_contexts(error['filename'], term, window))\n",
    "        print('')\n",
    "\n",
    "        \n",
    "print_errors(errors, clf, X_test, vec, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (10577) out of range (>= 4734)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-7a3b4e6d27b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m            \u001b[1;34m'maxdf_expt'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'%.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_df_expt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m            \u001b[1;34m'top_coef'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_top_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m            \u001b[1;34m'rem_feat'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'%.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_after_removing_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'worst'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m           },\n\u001b[0;32m     28\u001b[0m           outf, indent=2, sort_keys=True)\n",
      "\u001b[1;32m<ipython-input-199-b18b78d1732c>\u001b[0m in \u001b[0;36mtrain_after_removing_features\u001b[1;34m(X, y, vec, features_to_remove)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of_term\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, index, x)\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 656\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.pyc\u001b[0m in \u001b[0;36m_set_many\u001b[1;34m(self, i, j, x)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[0mcheck_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m         \u001b[0mcheck_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\OnlineSocial\\anaconda\\lib\\site-packages\\scipy\\sparse\\compressed.pyc\u001b[0m in \u001b[0;36mcheck_bounds\u001b[1;34m(indices, bound)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 raise IndexError('index (%d) out of range (>= %d)' %\n\u001b[1;32m--> 699\u001b[1;33m                                  (idx, bound))\n\u001b[0m\u001b[0;32m    700\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index (10577) out of range (>= 4734)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEQCAYAAACa+vIpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1664b908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "outf = open('output.txt', 'wt')\n",
    "clf.fit(X, y)\n",
    "\n",
    "json.dump({\n",
    "           'find_contexts': find_contexts(all_test_files[10], 'its', 10),\n",
    "           'pred_term': most_predictive_term_in_doc(X_test[10], clf, 1),\n",
    "           'top_errors': str(get_top_errors(X_test, y_test, all_test_files, clf)[0].items()),\n",
    "           'get_files': get_files(path + os.sep + 'train' + os.sep + 'pos')[:10],\n",
    "           'get_true_labels_pos': list(get_true_labels(get_files(path + os.sep + 'train' + os.sep + 'pos')[:5])),\n",
    "           'get_true_labels_neg': list(get_true_labels(get_files(path + os.sep + 'train' + os.sep + 'neg')[:5])),\n",
    "           'tokenize': tokenize('Hi-there-what_is UP????'),\n",
    "           'tokenize_punct': tokenize_with_punct('Hi-there-what_is UP????'),\n",
    "           'tokenize_not': tokenize_with_not('Hi-that is not cool . at all . not'),\n",
    "           'vec': sorted(do_vectorize(get_files(path + os.sep + 'train' + os.sep + 'pos')[:10])[0][8].nonzero()[1].tolist())[:10],\n",
    "           'vec_nonbinary': sorted(do_vectorize(get_files(path + os.sep + 'train' +\n",
    "                                                         os.sep + 'pos')[:10], binary=False)[0][8].data)[::-1][:10],\n",
    "           'cv10': '%.4f' % do_cross_validation(X[:100], y[:100], verbose=False, n_folds=10),\n",
    "           'cv3': '%.4f' % do_cross_validation(X[:100], y[:100], verbose=False, n_folds=3),\n",
    "           'nfolds_expt': ['%.4f' % v for v in compare_n_folds(filenames, y)],\n",
    "           'binary_expt': ['%.4f' % v for v in compare_binary(filenames, y)],\n",
    "           'tokenizer_expt': ['%.4f' % v for v in tokenizer_expt(filenames, y)],\n",
    "           'mindf_expt': ['%.4f' % v for v in min_df_expt(filenames, y)],\n",
    "           'maxdf_expt': ['%.4f' % v for v in max_df_expt(filenames, y)],\n",
    "           'top_coef': get_top_coefficients(clf, vec, n=3),\n",
    "           'rem_feat': '%.4f' % accuracy_score(train_after_removing_features(X.copy(), y, vec, ['worst']).predict(X_test), y_test),\n",
    "          },\n",
    "          outf, indent=2, sort_keys=True)\n",
    "outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
